package ring

import (
	"errors"
	"fmt"
	"hash/fnv"
	"math"
	"sync"

	"github.com/msmedes/ringhash/rbt"
)

// Config sets the amount of
type Config struct {
	VirtualNodes int
	LoadFactor   float64
}

type Ring struct {
	store        *rbt.Tree
	nodeMap      map[string]*node
	virtualNodes int

	totalLoad  int64
	loadFactor float64

	mu sync.RWMutex
}

func Uint64Comparator(o1, o2 interface{}) int {
	i1 := o1.(uint64)
	i2 := o2.(uint64)
	switch {
	case i1 > i2:
		return 1
	case i1 < i2:
		return -1
	default:
		return 0
	}

}

func NewRing(nodes []string, config *Config) *Ring {
	r := &Ring{
		store:        rbt.NewTreeWith(Uint64Comparator),
		nodeMap:      make(map[string]*node),
		virtualNodes: config.VirtualNodes,
		loadFactor:   config.LoadFactor,
	}

	for _, node := range nodes {
		r.Add(node)
	}

	return r
}

func (r *Ring) Add(node string) {
	r.mu.Lock()
	defer r.mu.Unlock()

	if _, ok := r.nodeMap[node]; ok {
		return
	}

	r.nodeMap[node] = newNode(node)
	nodeHash := hash(node)
	r.store.Put(nodeHash, node)

	// Generate virtual nodes, aka generate n nodes where n == VirtualNodes (set by config)
	// Nodes are generated by slightly modifying the name of the node being added and
	// hashing that.  So for example:
	// Node{name: foobar} would generate n more nodes like Node{name: foobar-1}, Node{name: foobar-2}...etc.
	// The idea I believe is to distribute the load.

	for i := 0; i < r.virtualNodes; i++ {
		virtualNodeKey := generateVirtualNodeKey(node, i)
		r.nodeMap[virtualNodeKey] = newNode(virtualNodeKey)
		virtualNodeHash := hash(virtualNodeKey)
		r.store.Put(virtualNodeHash, node)
	}

}

func generateVirtualNodeKey(key string, index int) string {
	return fmt.Sprintf("%s-%d", key, index)
}

func (r *Ring) Remove(node string) {
	r.mu.Lock()
	defer r.mu.Unlock()

	if _, ok := r.nodeMap[node]; !ok {
		fmt.Printf("Node with key %s not in ring", node)
		return
	}

	key := hash(node)
	r.store.Delete(key)

	for i := 0; i < r.virtualNodes; i++ {
		virtualNodeKey := generateVirtualNodeKey(node, i)
		virtualNodeHash := hash(virtualNodeKey)
		r.store.Delete(virtualNodeHash)
		delete(r.nodeMap, virtualNodeKey)
	}

	delete(r.nodeMap, node)
}

func (r *Ring) Get(key string) (string, error) {
	r.mu.Lock()
	defer r.mu.Unlock()

	if r.store.Size() == 0 {
		return "", errors.New("Empty ring")
	}

	var queryNode *rbt.Node

	queryHash := hash(key)
	queryNode = r.store.Nearest(queryHash)

	var iterations uint64

	for {
		if iterations >= r.store.Size() {
			return "", errors.New("Ring under max load")
		}
		if queryHash > queryNode.GetKey().(uint64) {
			successor := queryNode.Successor()
			if successor != nil {
				queryNode = successor
			} else {
				// we didn't find a successor so we start at the root of the tree
				queryNode = r.store.Root()
			}
		}
		// Is the load ok? if so return it, else we got to the successor
		if r.loadOk(queryNode.GetValue().(string)) {
			break
		}
		iterations++
		// retrieve the successor
		successor := queryNode.Successor()

		if successor == nil {
			// we didn't find a successor so we go to the lowest value in the tree
			// (aka looping back to the beginning in a hash ring)
			queryNode = r.store.Minimum()
		} else {
			// we found it
			queryNode = successor
		}
	}
	r.nodeMap[queryNode.GetValue().(string)].load++
	r.totalLoad++
	return queryNode.GetValue().(string), nil
}

type node struct {
	name string
	// active bool
	load int64
}

func newNode(name string) *node {
	return &node{
		name: name,
		// active: true,
		load: 0,
	}
}

func hash(s string) uint64 {
	h := fnv.New64a()
	h.Write([]byte(s))
	return h.Sum64()
}

func (r *Ring) NodeMap() map[string]*node {
	return r.nodeMap
}

func (r *Ring) Finished(node string) {
	if _, ok := r.nodeMap[node]; !ok {
		return
	}
	r.nodeMap[node].load--
	if r.totalLoad > 0 {
		r.totalLoad--
	}
}

func (r *Ring) loadOk(node string) bool {
	// bounded loads work the following way:
	// 1. Define a balancing factor for the ring (always greater than 1
	// but usually equal to or less than 2).
	// 2. When a new request arrives, compute the avg. load per server
	// (outstanding requests plus the current one, divided by number of nodes)
	// 3. Multiply avg. load by load factor to get a target load for each server
	// 4. Hash the request and go to the nearest server
	// 5. If that server is below it's capacity (avg. load * balancing factor),
	// assign the request to that server.
	// 6. Else, keep going to the next nearest server until you find one with
	// remaining capacity (you will always find one, since it's impossible for
	// every server to be above average)

	// does this node even exist
	n, ok := r.nodeMap[node]
	if !ok {
		fmt.Printf("%s is not in the host list", node)
		return false
	}

	avgLoad := float64(r.totalLoad+1) / float64(len(r.nodeMap))

	targetLoad := math.Ceil(avgLoad * r.loadFactor)

	if float64(n.load+1) <= targetLoad {
		return true
	}
	return false

}
